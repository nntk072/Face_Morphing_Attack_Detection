{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import ViTHybridImageProcessor, ViTHybridForImageClassification\n",
    "from transformers import AutoImageProcessor, SwinForImageClassification\n",
    "from PIL import Image\n",
    "import requests\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.optimize import brentq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Visual transformer model from https://huggingface.co/microsoft/swin-tiny-patch4-window7-224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "125f88cdd9894ab68922c48378efadb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/255 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nguyenl37\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\nguyenl37\\.cache\\huggingface\\hub\\models--microsoft--swin-tiny-patch4-window7-224. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07bdfec1dc864fe4be218d7f75316ea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/71.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7facb12551fe4f77a6d8332ddb58041b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/113M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\")\n",
    "model = SwinForImageClassification.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define data transforms (you can modify these based on your needs)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to a consistent size\n",
    "    transforms.ToTensor(),           # Convert images to tensors\n",
    "])\n",
    "\n",
    "# Define paths to your data folders\n",
    "# train_data_dir = '/u/45/muhammu2/data/Desktop/face/Evaluation/CASIA_dataset/training set/'\n",
    "# val_data_dir = '/u/45/muhammu2/data/Desktop/face/Evaluation/CASIA_dataset/testing set/'\n",
    "# test_data_dir = '/u/45/muhammu2/data/Desktop/face/Evaluation/REPLAY_ATTACK/test/'\n",
    "\n",
    "# Custom ImageFolder class to handle custom class names\n",
    "class CustomImageFolder(ImageFolder):\n",
    "    def find_classes(self, directory):\n",
    "        classes = ['attack1', 'real1']\n",
    "        class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "        return classes, class_to_idx\n",
    "train_data_dir = 'c:/Users/nguyenl37/OneDrive - Aalto University/University/First year/Project/Face_Morphing_Attack_Detection/Casia_dataset/train/'\n",
    "val_data_dir = 'c:/Users/nguyenl37/OneDrive - Aalto University/University/First year/Project/Face_Morphing_Attack_Detection/Casia_dataset/test/'\n",
    "test_data_dir = 'c:/Users/nguyenl37/OneDrive - Aalto University/University/First year/Project/Face_Morphing_Attack_Detection/Replay Attack dataset/test/'\n",
    "\n",
    "\n",
    "# Load your training, validation, and test datasets using ImageFolder\n",
    "# train_dataset = ImageFolder(root=train_data_dir, transform=transform)\n",
    "# val_dataset = ImageFolder(root=val_data_dir, transform=transform)\n",
    "# test_dataset = ImageFolder(root=test_data_dir, transform=transform)\n",
    "\n",
    "train_dataset = CustomImageFolder(root=train_data_dir, transform=transform)\n",
    "val_dataset = CustomImageFolder(root=val_data_dir, transform=transform)\n",
    "test_dataset = CustomImageFolder(root=test_data_dir, transform=transform)\n",
    "\n",
    "# If you want to access the labels for train, validation, and test datasets:\n",
    "train_labels = train_dataset.targets\n",
    "val_labels = val_dataset.targets\n",
    "test_labels = test_dataset.targets\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 8  # Adjust the batch size as needed\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a binary classification head\n",
    "class BinaryClassificationHead(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(BinaryClassificationHead, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Modify the Swin Transformer model for binary classification\n",
    "classifier_head = BinaryClassificationHead(768, 32)  # Adjust input size as needed\n",
    "model.classifier = classifier_head\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 0.9455, Validation Loss: 1.0344\n",
      "Epoch 1, EER: 0.5593, EER Threshold: 0.7167\n",
      "Epoch 2, Training Loss: 0.7960, Validation Loss: 0.6475\n",
      "Epoch 2, EER: 0.4704, EER Threshold: 0.4522\n",
      "Epoch 3, Training Loss: 0.7188, Validation Loss: 0.5745\n",
      "Epoch 3, EER: 0.5963, EER Threshold: 0.3211\n",
      "Epoch 4, Training Loss: 0.6469, Validation Loss: 0.5645\n",
      "Epoch 4, EER: 0.4519, EER Threshold: 0.2792\n",
      "Epoch 5, Training Loss: 0.6203, Validation Loss: 0.5643\n",
      "Epoch 5, EER: 0.4593, EER Threshold: 0.2781\n",
      "Epoch 6, Training Loss: 0.6048, Validation Loss: 0.5634\n",
      "Epoch 6, EER: 0.4889, EER Threshold: 0.2700\n",
      "Epoch 7, Training Loss: 0.5990, Validation Loss: 0.5630\n",
      "Epoch 7, EER: 0.4667, EER Threshold: 0.2657\n",
      "Epoch 8, Training Loss: 0.5949, Validation Loss: 0.5629\n",
      "Epoch 8, EER: 0.4889, EER Threshold: 0.2650\n",
      "Epoch 9, Training Loss: 0.5933, Validation Loss: 0.5628\n",
      "Epoch 9, EER: 0.4556, EER Threshold: 0.2639\n",
      "Epoch 10, Training Loss: 0.5918, Validation Loss: 0.5628\n",
      "Epoch 10, EER: 0.4926, EER Threshold: 0.2640\n",
      "Epoch 11, Training Loss: 0.5900, Validation Loss: 0.5630\n",
      "Epoch 11, EER: 0.4222, EER Threshold: 0.2656\n",
      "Early stopping at epoch 11\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Assuming model, train_loader, val_loader, test_loader, criterion, and optimizer are defined\n",
    "\n",
    "num_epochs = 50\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Initialize early stopping parameters\n",
    "patience = 5\n",
    "verbose = True\n",
    "delta = 0.001  # For validation loss improvements\n",
    "best_val_loss = float('inf')\n",
    "counter = 0\n",
    "best_eer_threshold = 0.5  # Placeholder for the EER threshold from the validation set\n",
    "\n",
    "# Initialize lists to store training and validation losses\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Training loop\n",
    "    for data, labels in train_loader:\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data).logits  # Get logits from model\n",
    "        loss = criterion(outputs, labels.unsqueeze(1).float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_labels = []  # Store true labels\n",
    "    val_scores = []  # To store probabilities for EER calculation\n",
    "    with torch.no_grad():\n",
    "        for val_data, val_labels_batch in val_loader:\n",
    "            val_data, val_labels_batch = val_data.to(device), val_labels_batch.to(device)\n",
    "            val_outputs = model(val_data).logits\n",
    "            val_loss += criterion(val_outputs, val_labels_batch.unsqueeze(1).float()).item()\n",
    "            \n",
    "            # Get probabilities (sigmoid for binary classification)\n",
    "            val_probs = torch.sigmoid(val_outputs).cpu().numpy()  # Convert logits to probabilities\n",
    "            val_scores.extend(val_probs)\n",
    "            val_labels.extend(val_labels_batch.cpu().numpy())\n",
    "\n",
    "    # Calculate average training and validation loss\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # EER Calculation on validation set\n",
    "    fpr, tpr, thresholds = roc_curve(val_labels, val_scores, pos_label=1)  # Ensure pos_label is set\n",
    "    fnr = 1 - tpr  # Calculate False Negative Rate\n",
    "    eer_threshold_idx = np.nanargmin(np.abs(fnr - fpr))  # Find index where FNR == FPR\n",
    "    eer_threshold = thresholds[eer_threshold_idx]  # EER threshold\n",
    "    eer_fpr = fpr[eer_threshold_idx]\n",
    "    eer_fnr = fnr[eer_threshold_idx]\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, EER: {eer_fpr:.4f}, EER Threshold: {eer_threshold:.4f}\")\n",
    "\n",
    "    # Early stopping based on validation loss\n",
    "    if avg_val_loss < best_val_loss - delta:\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_eer_threshold = eer_threshold  # Save the EER threshold for the test set\n",
    "        counter = 0\n",
    "        torch.save(model.state_dict(), 'best_model.pth')  # Save the best model\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            if verbose:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    # Append losses for plotting\n",
    "    train_losses.append(avg_train_loss)\n",
    "    val_losses.append(avg_val_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training completed and best EER threshold saved from validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Half Total Error Rate (HTER) on test set using EER threshold: 50.00%\n",
      "Area Under the ROC Curve (AUC) on test set: 63.03%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# --- Now calculate HTER on the test set using the EER threshold from validation ---\n",
    "test_labels = []\n",
    "test_scores = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Get model predictions\n",
    "        outputs = model(inputs)  # Get model predictions (SwinImageClassifierOutput)\n",
    "        scores = torch.sigmoid(outputs.logits).cpu().numpy()  # Access logits and compute probabilities\n",
    "\n",
    "        test_labels.extend(labels.cpu().numpy())  # Collect true labels\n",
    "        test_scores.extend(scores)  # Collect predicted scores (probabilities)\n",
    "\n",
    "# Classify test set based on the EER threshold from validation\n",
    "false_accepts = 0  # Counter for false accepts (impostor samples classified as genuine)\n",
    "false_rejects = 0  # Counter for false rejects (genuine samples classified as impostors)\n",
    "total_genuine = 0  # Counter for total genuine samples\n",
    "total_impostors = 0  # Counter for total impostor samples\n",
    "\n",
    "# Iterate over the test labels and scores to calculate false accepts and rejects\n",
    "for label, score in zip(test_labels, test_scores):\n",
    "    if label == 0:  # Genuine sample\n",
    "        total_genuine += 1\n",
    "        if score >= best_eer_threshold:  # False rejection (genuine classified as impostor)\n",
    "            false_rejects += 1\n",
    "    else:  # Impostor sample\n",
    "        total_impostors += 1\n",
    "        if score < best_eer_threshold:  # False acceptance (impostor classified as genuine)\n",
    "            false_accepts += 1\n",
    "\n",
    "# Calculate FAR and FRR while avoiding division by zero\n",
    "far = false_accepts / total_impostors if total_impostors > 0 else 0  # False Acceptance Rate\n",
    "frr = false_rejects / total_genuine if total_genuine > 0 else 0  # False Rejection Rate\n",
    "\n",
    "# Calculate HTER on the test set\n",
    "hter = (far + frr) / 2  # Half Total Error Rate\n",
    "\n",
    "# Output the results\n",
    "print(f\"Half Total Error Rate (HTER) on test set using EER threshold: {hter * 100:.2f}%\")\n",
    "\n",
    "# Calculate AUC on test set\n",
    "auc = roc_auc_score(test_labels, test_scores)\n",
    "print(f\"Area Under the ROC Curve (AUC) on test set: {auc * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
